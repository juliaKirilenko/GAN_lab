{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  (loss = :mrl, opt = :sgd, agg = :sum, constr = :maxval) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re\n",
    "from collections import defaultdict\n",
    "import nltk  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('parserEcho8.csv', engine='python', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['name', 'desc']\n",
    "data = data.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    doc = re.sub('\\W', ' ', doc).lower().split()\n",
    "    doc = [lemmatizer.lemmatize(word) for word in doc]\n",
    "    d = defaultdict(int)\n",
    "    for word in doc:\n",
    "        d[word] += 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(feature):\n",
    "    feature = feature.map(tokenize)\n",
    "    for d in feature:\n",
    "        for w, v in d.items():\n",
    "            vocab[w] += v\n",
    "    return feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = get_vocab(data.name)\n",
    "desc = get_vocab(data.desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'его': 1,\n",
       "             'обвиняют': 1,\n",
       "             'в': 2,\n",
       "             'десяти': 1,\n",
       "             'эпизодах': 1,\n",
       "             'сексуального': 1,\n",
       "             'насилия': 1,\n",
       "             'том': 1,\n",
       "             'числе': 1,\n",
       "             'и': 1,\n",
       "             'над': 1,\n",
       "             'несовершеннолетними': 1})"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2 = [x for x in sorted(vocab.items(), key=lambda x: -x[1]) if x[1] > 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab3 = defaultdict(int)\n",
    "count = 1\n",
    "for value,ind in vocab2:\n",
    "    vocab3[value] = count\n",
    "    count=count+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16482"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_features(features):\n",
    "    new_docs = list()\n",
    "    for doc in features:\n",
    "        vector = list()\n",
    "        for word in doc:\n",
    "            if vocab3[word]!=0:\n",
    "                vector.append(vocab3[word])\n",
    "        new_docs.append(vector)\n",
    "    return new_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = new_features(names)\n",
    "new_desc = new_features(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = np.random.randn(50, len(vocab2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxval = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emb = np.random.normal(0,1.0,(emb_size, len(vocab2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 16482)"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31128327,  0.52594134,  0.3332039 , ...,  1.19904194,\n",
       "         0.56444583,  1.0119893 ],\n",
       "       [-0.30882589, -1.45049469,  0.1154132 , ..., -0.09901407,\n",
       "        -1.3866041 ,  0.65642323],\n",
       "       [ 0.59555886, -1.31364724, -1.0336686 , ..., -0.20656153,\n",
       "        -0.36972137,  0.8361492 ],\n",
       "       ...,\n",
       "       [ 0.65025709, -0.49581775, -1.93419397, ...,  1.30710333,\n",
       "         0.89416039,  1.45488112],\n",
       "       [-1.25784098,  0.85298139, -1.50401125, ..., -0.73544384,\n",
       "         1.92932706,  0.22883619],\n",
       "       [ 0.93105808,  0.09798943, -0.73553983, ..., -1.16811624,\n",
       "        -1.27944891, -0.89303161]])"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = new_names[:1000]\n",
    "train_names = new_names[1000:3000]\n",
    "test_desc = new_desc[:1000]\n",
    "train_desc = new_desc[1000:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "test_data.append(test_names)\n",
    "test_data.append(test_desc)\n",
    "train_data = []\n",
    "train_data.append(train_names)\n",
    "train_data.append(train_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg(m, idx):\n",
    "    agg_arr = list()\n",
    "    for text in idx:\n",
    "        arr = np.zeros((1,emb_size))\n",
    "        for word in text:\n",
    "            arr = arr + m[:,word]\n",
    "        agg_arr.append(arr)\n",
    "    return agg_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_hinge(u, v, vh, gamma = 1.0):\n",
    "    loss = gamma - np.dot(u,v.transpose()) + np.dot(u,vh.transpose())\n",
    "    if loss > 0:\n",
    "        return (vh - v, -u, u)\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(embed, idx, Δ, η):\n",
    "    d = -Δ*η\n",
    "    for i in idx:\n",
    "        emb[:, i] +=d[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tuples(emb, idx, η):\n",
    "    embs = agg(emb, idx)\n",
    "    Δs = backward_hinge(embs[0],embs[1],embs[2])\n",
    "    if(Δs == None):\n",
    "        return\n",
    "    for i, Δ in zip(idx, Δs):\n",
    "        update(emb, i, Δ, η)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31128327,  0.52594134,  0.3332039 , ...,  1.19904194,\n",
       "         0.56444583,  1.0119893 ],\n",
       "       [-0.30882589, -1.45049469,  0.1154132 , ..., -0.09901407,\n",
       "        -1.3866041 ,  0.65642323],\n",
       "       [ 0.59555886, -1.31364724, -1.0336686 , ..., -0.20656153,\n",
       "        -0.36972137,  0.8361492 ],\n",
       "       ...,\n",
       "       [ 0.65025709, -0.49581775, -1.93419397, ...,  1.30710333,\n",
       "         0.89416039,  1.45488112],\n",
       "       [-1.25784098,  0.85298139, -1.50401125, ..., -0.73544384,\n",
       "         1.92932706,  0.22883619],\n",
       "       [ 0.93105808,  0.09798943, -0.73553983, ..., -1.16811624,\n",
       "        -1.27944891, -0.89303161]])"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_maxval(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31128327,  0.52594134,  0.3332039 , ...,  1.19904194,\n",
       "         0.56444583,  1.0119893 ],\n",
       "       [-0.30882589, -1.45049469,  0.1154132 , ..., -0.09901407,\n",
       "        -1.3866041 ,  0.65642323],\n",
       "       [ 0.59555886, -1.31364724, -1.0336686 , ..., -0.20656153,\n",
       "        -0.36972137,  0.8361492 ],\n",
       "       ...,\n",
       "       [ 0.65025709, -0.49581775, -1.93419397, ...,  1.30710333,\n",
       "         0.89416039,  1.45488112],\n",
       "       [-1.25784098,  0.85298139, -1.50401125, ..., -0.73544384,\n",
       "         1.92932706,  0.22883619],\n",
       "       [ 0.93105808,  0.09798943, -0.73553983, ..., -1.16811624,\n",
       "        -1.27944891, -0.89303161]])"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_maxval(embed):\n",
    "    for i in range(len(embed)):\n",
    "        for j in range(len(embed[0])):\n",
    "            if abs(emb[i,j])>maxval:\n",
    "                emb[i,j]=maxval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_epoch(emb, data, η):\n",
    "    first = np.random.permutation(len(data[0]))\n",
    "    second = np.roll(first, 1)\n",
    "    count=0\n",
    "    for (f, s) in zip(first, second):\n",
    "        if count>50:\n",
    "            count = 0\n",
    "            check_maxval(emb)\n",
    "        u = data[0][f]\n",
    "        v = data[1][f]\n",
    "        train_tuples(emb, (u, v, data[1][s]), η)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k(vec, i, k):\n",
    "    count = 0\n",
    "    for index in range(len(vec[0])):\n",
    "        if vec[0,i] < vec[0,index]:\n",
    "            count=count+1\n",
    "    if count<k:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(emb, data, k = 10):\n",
    "    n_test = len(data[0])\n",
    "    desc_emb = np.zeros((emb_size,n_test))\n",
    "    recall=0\n",
    "    \n",
    "    for i in range(n_test):\n",
    "        arr = np.zeros((1,emb_size))\n",
    "        for word in data[1][i]:\n",
    "            arr = arr + emb[:,word]\n",
    "        desc_emb[:,i] = arr  \n",
    "        \n",
    "    for i in range(n_test):\n",
    "        title_emb = np.zeros((1,emb_size))\n",
    "        for word in data[0][i]:\n",
    "            title_emb = title_emb + emb[:,word]\n",
    "        \n",
    "        if top_k(np.dot(title_emb, desc_emb), i, k)==True:\n",
    "            recall=recall+1\n",
    "            \n",
    "    return recall / n_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(emb, train_data, test_data, n_epochs, η):\n",
    "    for epoch in range(n_epochs):\n",
    "        t = train_on_epoch(emb, train_data, η)\n",
    "        recall = recall_at_k(emb, test_data)\n",
    "        print(epoch)\n",
    "        print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in add\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in greater\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in add\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.567\n",
      "1\n",
      "0.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in add\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in add\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in subtract\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in add\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in add\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in add\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in add\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in add\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in add\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0.984\n",
      "3\n",
      "0.991\n",
      "4\n",
      "0.989\n",
      "5\n",
      "0.99\n",
      "6\n",
      "0.99\n",
      "7\n",
      "0.994\n",
      "8\n",
      "0.995\n",
      "9\n",
      "0.995\n",
      "10\n",
      "0.995\n",
      "11\n",
      "0.995\n",
      "12\n",
      "0.995\n",
      "13\n",
      "0.995\n",
      "14\n",
      "0.995\n",
      "15\n",
      "0.995\n",
      "16\n",
      "0.995\n",
      "17\n",
      "0.996\n",
      "18\n",
      "0.996\n",
      "19\n",
      "0.996\n"
     ]
    }
   ],
   "source": [
    "train(emb, train_data, test_data, 20, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
